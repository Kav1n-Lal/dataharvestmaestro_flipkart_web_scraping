{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\kavin\\anaconda3\\lib\\site-packages (2.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\kavin\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\kavin\\anaconda3\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\kavin\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\kavin\\anaconda3\\lib\\site-packages (from pandas) (1.24.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\kavin\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: webdriver-manager in c:\\users\\kavin\\anaconda3\\lib\\site-packages (4.0.1)\n",
      "Requirement already satisfied: requests in c:\\users\\kavin\\anaconda3\\lib\\site-packages (from webdriver-manager) (2.31.0)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\kavin\\anaconda3\\lib\\site-packages (from webdriver-manager) (0.21.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\kavin\\anaconda3\\lib\\site-packages (from webdriver-manager) (23.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\kavin\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kavin\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\kavin\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kavin\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (2023.7.22)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kavin\\AppData\\Local\\Temp\\ipykernel_16424\\1852715827.py:13: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "! pip install pandas\n",
    "! pip install webdriver-manager\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page no 1 scraped\n",
      "page no 2 scraped\n",
      "page no 3 scraped\n",
      "page no 4 scraped\n",
      "page no 5 scraped\n",
      "page no 6 scraped\n",
      "page no 7 scraped\n",
      "page no 8 scraped\n",
      "page no 9 scraped\n",
      "page no 10 scraped\n",
      "page no 11 scraped\n",
      "page no 12 scraped\n",
      "page no 13 scraped\n",
      "page no 14 scraped\n",
      "page no 15 scraped\n",
      "page no 16 scraped\n",
      "page no 17 scraped\n",
      "page no 18 scraped\n",
      "page no 19 scraped\n",
      "page no 20 scraped\n",
      "page no 21 scraped\n",
      "page no 22 scraped\n",
      "page no 23 scraped\n",
      "page no 24 scraped\n",
      "page no 25 scraped\n",
      "page no 26 scraped\n",
      "page no 27 scraped\n",
      "page no 28 scraped\n",
      "page no 29 scraped\n",
      "page no 30 scraped\n",
      "page no 31 scraped\n",
      "page no 32 scraped\n",
      "page no 33 scraped\n",
      "page no 34 scraped\n",
      "page no 35 scraped\n",
      "page no 36 scraped\n",
      "page no 37 scraped\n",
      "page no 38 scraped\n",
      "page no 39 scraped\n",
      "page no 40 scraped\n",
      "page no 41 scraped\n",
      "scraped until page_no 42\n",
      "errors ['error']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "a=[]\n",
    "website=[]\n",
    "brand_name=[]\n",
    "rating=[]\n",
    "rating_count=[]\n",
    "reviews=[]\n",
    "discount_price=[]\n",
    "original_price=[]\n",
    "discount_percent=[]\n",
    "bank_offers=[]\n",
    "final_spec=[]\n",
    "delivery=[] \n",
    "\n",
    "\n",
    "\n",
    "def scrape(url):\n",
    "    # load the web page\n",
    "    #driver.get(url)\n",
    "    # set maximum time to load the web page in seconds\n",
    "    #driver.implicitly_wait(10)\n",
    "    \n",
    "    # collect data that are withing the id of contents\n",
    "    #link_a_tags = driver.find_elements(By.XPATH, '//a[@class=\"_1fQZEK\"]')\n",
    "    \n",
    " \n",
    "    links=[]\n",
    "    for link in link_a_tags:\n",
    "        links.append(link.get_attribute(\"href\"))\n",
    "    #print(links)\n",
    "     \n",
    "    for each_link in links:\n",
    "        try:\n",
    "            website.append(each_link)\n",
    "            driver.get(each_link)\n",
    "            driver.implicitly_wait(3)\n",
    "            brand_name.append(driver.find_element(By.XPATH,'//span[@class=\"B_NuCI\"]').text)\n",
    "            try:\n",
    "                rating.append(driver.find_element(By.XPATH,'//div[@class=\"_3LWZlK\"]').text)\n",
    "            except:\n",
    "                rating.append(np.nan)\n",
    "            try:\n",
    "                rating_count.append(driver.find_element(By.XPATH,'(//div[@class=\"_3_L3jD\"]//span)[4]').text)\n",
    "            except:\n",
    "                rating_count.append(np.nan)\n",
    "            try:\n",
    "                reviews.append(driver.find_element(By.XPATH,'(//div[@class=\"_3_L3jD\"]//span)[6]').text)\n",
    "            except:\n",
    "                reviews.append(np.nan)\n",
    "            try:\n",
    "                discount_price.append(driver.find_element(By.XPATH,'//div[@class=\"_30jeq3 _16Jk6d\"]').text)\n",
    "            except:\n",
    "                discount_price.append(np.nan)\n",
    "            try:\n",
    "                o=driver.find_elements(By.XPATH,'//div[@class=\"_3I9_wc _2p6lqe\"]')\n",
    "                op=[i.text for i in o]\n",
    "                original_price.append(' '.join(op))\n",
    "            except:\n",
    "                original_price.append(np.nan)\n",
    "            try:\n",
    "                discount_percent.append(driver.find_element(By.XPATH,'//div[@class=\"_3Ay6Sb _31Dcoz\"]/span').text)\n",
    "            except:\n",
    "                discount_percent.append(np.nan)\n",
    "            try:\n",
    "                d1=[]\n",
    "                driver.find_element(By.XPATH,'//div[@class=\"IMZJg1\"]/span').click()\n",
    "                r=1\n",
    "                while r<len(driver.find_elements(By.XPATH,'//li[@class=\"_16eBzU col\"]')):\n",
    "                    \n",
    "                    try:\n",
    "                        k=f'(//li[@class=\"_16eBzU col\"])[{r}]/span'\n",
    "                        bk=driver.find_elements(By.XPATH,k)\n",
    "                        d=[i.text for i in bk]\n",
    "                        \n",
    "                        #bank_offers.append(' '.join(d))\n",
    "                        try:\n",
    "                            d.append(driver.find_element(By.XPATH,f'(//div[@ class=\"Bv11UC _1qNw3R\"])[{r}]').text)\n",
    "                            d1.append((' '.join(d)))\n",
    "                            #bank_offers.append((' '.join(d)))\n",
    "                        except:\n",
    "                            d1.append((' '.join(d)))\n",
    "                            pass\n",
    "                    except:\n",
    "                        bank_offers.append('no offers')\n",
    "                    \n",
    "                    \n",
    "                    r+=1\n",
    "                bank_offers.append(tuple(d1))\n",
    "            except:\n",
    "                bank_offers.append(np.nan)\n",
    "            #specifications\n",
    "            driver.find_element(By.XPATH,'//button[@class=\"_2KpZ6l _1FH0tX\"]').click()\n",
    "            try:\n",
    "                spec_container=driver.find_elements(By.XPATH,'//div[@class=\"flxcaE\"]')\n",
    "                specification=[]\n",
    "                sp=[]\n",
    "                \n",
    "                for j in range(1,len(spec_container)+1):\n",
    "                    spec=spec_container[j-1].text\n",
    "                   \n",
    "                    key=driver.find_elements(By.XPATH,f'(//table[@class=\"_14cfVK\"])[{j}]//td[@class=\"_1hKmbr col col-3-12\"]')\n",
    "                    value=driver.find_elements(By.XPATH,f'(//table[@class=\"_14cfVK\"])[{j}]//li[@class=\"_21lJbe\"]')\n",
    "                    \n",
    "                    for i in range(len(key)):\n",
    "                        sp.append((key[i].text,value[i].text))\n",
    "                  \n",
    "                    \n",
    "                    specification.append({spec:dict(sp)})\n",
    "                    sp.clear()\n",
    "                final_spec.append(specification)\n",
    "            except:\n",
    "                final_spec.append(np.nan)\n",
    "            #delivery\n",
    "            try:\n",
    "                d=[driver.find_element(By.XPATH,'(//div[@class=\"_3XINqE\"])[1]').text]\n",
    "                delivery.append(d)\n",
    "            except:\n",
    "                delivery.append(np.nan)\n",
    "            \n",
    "        except:\n",
    "            a.append('error')\n",
    "            pass\n",
    "\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "\n",
    "page=1\n",
    "while True:\n",
    "    #try:\n",
    "    # Define the URL\n",
    "    url = f\"https://www.flipkart.com/q/premium-laptops?page={page}\"\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "\n",
    "    driver.get(url)\n",
    "    link_a_tags = driver.find_elements(By.XPATH, '//a[@class=\"_1fQZEK\"]')\n",
    "    if len(link_a_tags)!=0:\n",
    "        scrape(url)\n",
    "        df=pd.DataFrame({\n",
    "        'brand_name':brand_name,\n",
    "        'rating':rating,\n",
    "        'rating_count':rating_count,\n",
    "        'reviews':reviews,\n",
    "        'discount_price':discount_price,\n",
    "        'original_price':original_price,\n",
    "        'discount_percent':discount_percent,'bank_offers':bank_offers,\n",
    "        'delivery':delivery,'specification':final_spec})\n",
    "        \n",
    "        df.to_csv('laptop.csv',index=False)\n",
    "        print('page no',page,'scraped')\n",
    "        page+=1\n",
    "    else:\n",
    "        print('scraped until page_no',page)\n",
    "        driver.quit()\n",
    "        break\n",
    "    \n",
    "    #except:\n",
    "       \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('errors',a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flipkart_harvest",
   "language": "python",
   "name": "flipkart_harvest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
